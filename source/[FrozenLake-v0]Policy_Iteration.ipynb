{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2EfdvH5hSDXm"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iRO2o9axS4bS"
   },
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jNbLFNwsXhNF"
   },
   "outputs": [],
   "source": [
    "def initialization(env):\n",
    "    policy = np.random.randint(4, size=env.observation_space.n, dtype=np.int)\n",
    "    \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rufJ7WjSYGEG"
   },
   "outputs": [],
   "source": [
    "policy = initialization(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Go1TgtWAm8JU",
    "outputId": "117afe11-2efa-42c5-abcf-f4e95f0cb605"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 1, 3, 0, 0, 3, 1, 3, 3, 2, 2, 1, 0, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-llzIO6xU9bm"
   },
   "outputs": [],
   "source": [
    "def policy_evaluation(env, policy, max_iters, gamma):\n",
    "    v_values = np.zeros(env.observation_space.n)\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        prev_v_values = np.copy(v_values)\n",
    "\n",
    "        # Compute the value for state\n",
    "        for state in range(env.observation_space.n):\n",
    "            # Compute the q-value for each action\n",
    "            action = policy[state]\n",
    "            q_value = 0\n",
    "                # Loop through each possible outcome\n",
    "            for prob, next_state, reward, done in env.P[state][action]:\n",
    "                q_value += prob * (reward + gamma * prev_v_values[next_state])\n",
    "                \n",
    "            \n",
    "            # Select the best action\n",
    "            v_values[state] = q_value\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.all(np.isclose(v_values, prev_v_values)):\n",
    "#             print(f'Converged at {i}-th iteration.')\n",
    "            break\n",
    "    \n",
    "    return v_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k68jaXmJXTvR",
    "outputId": "ab942409-b6e2-4936-b6a3-269f441d9a76"
   },
   "outputs": [],
   "source": [
    "v_values = policy_evaluation(env, policy, max_iters=1000, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "USWIyd1-XaAW",
    "outputId": "104699b8-c1df-40bc-cafa-62143acd51ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(env, old_policy, old_v_values, gamma):\n",
    "    policy = np.zeros(env.observation_space.n, dtype=np.int)\n",
    "        # Compute the value for state\n",
    "    for state in range(env.observation_space.n):\n",
    "        q_values = []\n",
    "            # Compute the q-value for each action\n",
    "        for action in range(env.action_space.n):\n",
    "            q_value = 0\n",
    "                # Loop through each possible outcome\n",
    "            for prob, next_state, reward, done in env.P[state][action]:\n",
    "                q_value += prob * (reward + gamma * old_v_values[next_state])\n",
    "                \n",
    "            q_values.append(q_value)\n",
    "            \n",
    "            # Select the best action\n",
    "        best_action = np.argmax(q_values)\n",
    "        policy[state] = best_action\n",
    "        \n",
    "        # Check convergence\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_improvement(env, policy, v_values, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(env, max_iters, gamma):\n",
    "    policy = initialization(env)\n",
    "    for i in range(max_iters):\n",
    "        v_values = policy_evaluation(env, policy, max_iters=1000, gamma=0.9)\n",
    "        new_policy = policy_improvement(env, policy, v_values, gamma=0.9)\n",
    "        if (np.array_equal(policy, new_policy)):\n",
    "            print(f'Converged at {i}-th iteration.')\n",
    "            break\n",
    "        policy = new_policy.copy()\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at 5-th iteration.\n"
     ]
    }
   ],
   "source": [
    "policy = policy_iteration(env, max_iters=1000, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "cca5B02dZAl2"
   },
   "outputs": [],
   "source": [
    "def play(env, policy):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    steps = 0\n",
    "#     time.sleep(1)\n",
    "#     display.clear_output(wait=True)\n",
    "    while not done:\n",
    "        action = policy[state]\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "#         print(f'Step {steps}')\n",
    "#         env.render()\n",
    "#         time.sleep(0.2)\n",
    "#         if not done:\n",
    "#            display.clear_output(wait=True)\n",
    "        state = next_state\n",
    "\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w46kFNsGZ2o1",
    "outputId": "f369170f-378a-49c2-94fe-c84dfed56569"
   },
   "outputs": [],
   "source": [
    "play(env, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-nrMm7uyZ5we"
   },
   "outputs": [],
   "source": [
    "def play_multiple_times(env, policy, max_episodes):\n",
    "    success = 0\n",
    "\n",
    "    for i in range(max_episodes):\n",
    "        reward = play(env, policy)\n",
    "\n",
    "        if reward > 0:\n",
    "            success += 1\n",
    "    \n",
    "    print(f'Number of successes: {success}/{max_episodes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4K4We01a6gm",
    "outputId": "09c06b1f-d4ea-442b-eaea-cc8244b6f084",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successes: 733/1000\n"
     ]
    }
   ],
   "source": [
    "play_multiple_times(env, policy, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EAA1Iq09GWGz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ValueIteration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
